

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/lufei.png">
  <link rel="icon" href="/img/lufei.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="张富利">
  <meta name="keywords" content="">
  
    <meta name="description" content="AbstractBeamBand是一种手腕佩戴系统，使用超声波波束形成的手势感应。使用一组安置在手腕上的小型换能器，我们可以集成声波前缘，以特定的角度和焦距投射声波能量。这使得我们可以从多个角度，以一种类似光栅扫描的方式，用听不清的声音来研究手的表面几何结构。我们使用产生的特征反射来识别8帧每秒的手部姿势。在我们的用户研究中，我们发现BeamBand支持六类手势设置，其精确度为94.6%。即使在整">
<meta property="og:type" content="article">
<meta property="og:title" content="BeamBand-Hand Gesture Sensing with Ultrasonic Beamforming">
<meta property="og:url" content="https://zhangfuli.github.io/2020/02/27/BeamBand-Hand-Gesture-Sensing-with-Ultrasonic-Beamforming/index.html">
<meta property="og:site_name" content="Hello, Zhangfuli">
<meta property="og:description" content="AbstractBeamBand是一种手腕佩戴系统，使用超声波波束形成的手势感应。使用一组安置在手腕上的小型换能器，我们可以集成声波前缘，以特定的角度和焦距投射声波能量。这使得我们可以从多个角度，以一种类似光栅扫描的方式，用听不清的声音来研究手的表面几何结构。我们使用产生的特征反射来识别8帧每秒的手部姿势。在我们的用户研究中，我们发现BeamBand支持六类手势设置，其精确度为94.6%。即使在整">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75416648-d482c700-5969-11ea-9eb4-0ade600449dd.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75419620-38f55480-5971-11ea-89fd-824c47f1babd.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75420939-216b9b00-5974-11ea-809b-23fcf9da053d.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75421494-588e7c00-5975-11ea-8960-fe3232a0cb37.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75423470-bae97b80-5979-11ea-8e21-2498b6787e91.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75425874-83310280-597e-11ea-9e26-70a1215af1c4.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/17808702/75424512-b8882100-597b-11ea-9ba2-f030a77fc1a9.png">
<meta property="article:published_time" content="2020-02-27T04:09:53.000Z">
<meta property="article:modified_time" content="2020-03-08T12:59:47.521Z">
<meta property="article:author" content="张富利">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/17808702/75416648-d482c700-5969-11ea-9eb4-0ade600449dd.png">
  
  
  
  <title>BeamBand-Hand Gesture Sensing with Ultrasonic Beamforming - Hello, Zhangfuli</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"zhangfuli.github.io","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jeffrey&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="BeamBand-Hand Gesture Sensing with Ultrasonic Beamforming"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2020-02-27 12:09" pubdate>
          2020年2月27日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          75 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">BeamBand-Hand Gesture Sensing with Ultrasonic Beamforming</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>BeamBand是一种手腕佩戴系统，使用超声波波束形成的手势感应。使用一组安置在手腕上的小型换能器，我们可以集成声波前缘，以特定的角度和焦距投射声波能量。这使得我们可以从多个角度，以一种类似光栅扫描的方式，用听不清的声音来研究手的表面几何结构。我们使用产生的特征反射来识别8帧每秒的手部姿势。在我们的用户研究中，我们发现BeamBand支持六类手势设置，其精确度为94.6%。即使在整个过程中，当传感器被移除并重新戴上之后，准确率仍然很高:89.4%。我们描述了我们的软件和硬件，以及未来集成到设备，如智能手表和VR控制器的途径。</p>
<h2 id="1、Introduction"><a href="#1、Introduction" class="headerlink" title="1、Introduction"></a>1、Introduction</h2><p>无论是智能手表还是AR/VR系统，强大的手势检测都有望丰富用户界面，提高沉浸感。不幸的是，在不使用手的情况下识别手势(例如，手套，控制器)已经被证明是具有挑战性的，这激发了识别新方法的需求。之前的研究包括利用肌电图，生物技术，电阻抗断层成像，轮廓感知，和磨损相机。虽然每种方法都有其优点和缺点，但一个共同的缺点是用户和会话之间的鲁棒准确性。</p>
<p>在这篇文章中，我们介绍了我们在BeamBand上的工作，这是一种利用声波束形成的用于佩戴手势感知的新方法。我们使用沿手腕轮廓布置的小型空中超声波传感器(图1A)，它提供了一个稳定的有利位置来捕捉手部姿势。利用主动波束形成技术，我们将超声引导和聚焦到手部感兴趣的区域(图1B)。我们还将我们的传感器进行多路复用，从稍微不同的角度捕获波束形成的反射(图1B)，为机器学习驱动的手势识别提供丰富的信号(图1C)。</p>
<p>为了评估BeamBand的识别性能，我们进行了一项10人参与的研究，采用了文献中的两个手势集，以便进行直接比较(即，而不是开发自定义集)。第一组包含七个手部姿势，而第二组有六个沿着三个旋转轴的关节。在这两个手势集上，BeamBand的准确率分别为92.5%和94.6%。更独特的是，在摘除和重新戴上带子后，准确率仍然很高，分别为86.0%和89.4%。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75416648-d482c700-5969-11ea-9eb4-0ade600449dd.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h2 id="2、Related-work"><a href="#2、Related-work" class="headerlink" title="2、Related work"></a>2、Related work</h2><p>首先，我们回顾与手势识别应用领域相关的先前工作。然后我们开始使用声学反射测量法，特别关注HCI文献。最后，我们更详细地讨论了波束形成，因为这是我们的主要技术方法，并回顾了在HCI领域中使用它的少数系统。</p>
<h3 id="2-1-Hand-Gesture-Sensing"><a href="#2-1-Hand-Gesture-Sensing" class="headerlink" title="2.1 Hand Gesture Sensing"></a>2.1 Hand Gesture Sensing</h3><p>手的姿态和运动的健壮感知一直是HCI的一个长期目标。最直接的方法是直接测量双手，例如，手套中含有加速计、应变计和电容传感器。这些方法通常将传感器放置在适合其手势任务的位置。例如，Perng等人的把加速度计放在指尖，以进行交互，例如指向和哪根手指被举起。Whitmire等人使用导电织物作为电容传感器来检测手指和拇指之间的相互作用。</p>
<p>稍微不那么显眼和有侵略性的是那些试图从手腕或手臂感知手的系统。BeamBand就属于这一类。最流行的方法之一是使用光学传感器来检测用户手势时手部的几何变化。例如，腕旋使用一组红外近距离传感器来检测手相对于手腕的角度。另一种光学方法是使用摄像机观察手势并重建手部的三维模型。摄像机也可以安装在头戴式显示器上。还有大量的研究利用压力、红外和电容传感器来利用手臂轮廓的变化。</p>
<p>除了查询手的外部状态外，人们还利用身体内部的信号来确定手的状态。一种常用的方法是肌电描记术(EMG)，它能被动地检测肌肉收缩发出的电信号。主动感知也被探索过，如电阻抗断层成像，它被用来感知手臂内部结构的变化，用于手势感知。</p>
<p>与BeamBand最相关的是使用声信号的方法。例如，Amento等人的[1]、Hambone[8]、Skinput[15]和触觉老师[16]将被动的声学传感器置于皮肤上，以听由手指轻敲、轻弹和挤压产生的微振动。最近，研究表明，现成的智能手表也可以检测这些信号。方法和[46]提供了一个很好的调查手腕磨损的传感方法(包括声学)。</p>
<h3 id="2-2-Acoustic-Reflectometry-in-HCI"><a href="#2-2-Acoustic-Reflectometry-in-HCI" class="headerlink" title="2.2 Acoustic Reflectometry in HCI"></a>2.2 Acoustic Reflectometry in HCI</h3><p>BeamBand是建立在超声反射测量原理上的，它通过发射结构声波和测量反射信号来检测感兴趣的物体。声音的飞行时间可以用来推断物体的距离，这是可以得到的最基本的信息。一个例子是单发射极声纳，它已经在海洋应用中使用了大约一个世纪，还有回声定位，动物使用的时间要长得多。除了飞行时间，反射的振幅(包括不同频率的非线性阻尼)和多路径效应也可以揭示环境的各个方面(例如，材料属性、房间几何形状)。</p>
<p>在HCI文献中，声学反射法最常见的形式是用于测距的低成本声纳传感器。例如，“触摸之声”[31]和“指压”[53]都使用体内声纳探测手势。在空气声呐传感器中，指向身体的[25]探测用户手臂上的触摸输入。通过测量反射的多普勒频移来检测手势[3]和在前臂[31]上的划动(HCI中超声多普勒传感的测量见[36])。</p>
<h3 id="2-3-Acoustic-Beamforming"><a href="#2-3-Acoustic-Beamforming" class="headerlink" title="2.3 Acoustic Beamforming"></a>2.3 Acoustic Beamforming</h3><p>波束形成可以在任何传输介质中实现，尽管它最常应用于无线电波(如雷达、无线通信)和声音(如医用超声)。当多个波前被创造，信号经历建设性和破坏性的干扰，这可以用来形成受控的能量束，因此这项技术的名字。参见图2和视频图，以获得简明的视觉入门知识(以获得更全面的背景知识)。波束形成也可以反过来使用。[30]，使用一组被动接收器，例如，定位房间内的声音[2]或手指快照[14]。</p>
<p>在工作中最类似波束带的是海上应用的多发射极/接收器拖曳声呐阵列。在单发射极声纳(不管接收器的数量)中，遇到的第一个物体通常反射最大的信号。然而，有了多个发射器，就有可能协调波束形成“ping信号”，将能量聚焦在不同距离的感兴趣区域。这类似于医学超声[11]，它使用波束形成来聚焦身体特定深度的声波能量，然后本质上是光栅扫描来产生一个二维图像(在EchoFlex中用于手势感知)。这些装置花费数千美元，使用MHz范围的超声波，并且需要液体或凝胶来连接传感介质。BeamBand使用较低频率的40khz超声波，它可以更容易地在空气中传播，并与表面相互作用，而无需使用界面介质。超声波束形成也被用于触觉和空气悬浮在HCI文献。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75419620-38f55480-5971-11ea-89fd-824c47f1babd.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h2 id="3、PILOT-EXPERIMENTS"><a href="#3、PILOT-EXPERIMENTS" class="headerlink" title="3、PILOT EXPERIMENTS"></a>3、PILOT EXPERIMENTS</h2><p>在开发我们的系统之前，我们试图更好地理解波束形成是如何在多发射极机载装置中工作的。我们从软件模拟开始，改变7个均匀间隔的发射器的相对相位，输出40 kHz波(室温空气中1020mbar的~8.5 mm波长)，使我们能够控制波前的角度和焦点(图2，顶部)。为了验证我们的理论模型，我们还进行了真实世界的物理实验，捕捉更复杂的相互作用，如传感器阻抗失配、多路径干扰和环境噪声。我们的物理传感器阵列匹配我们的软件模拟:七个均匀间隔，40khz的传感器。和以前一样，我们改变了发射源的相对相位，以创建不同的发射角和焦距。</p>
<p>为了捕获和可视化超声波，我们在数控龙门架上安装了一个内部相关的传感器。我们在12.4×12.4厘米的正方形范围内沿着4毫米的网格移动这个龙门架。在网格上的每个点上，传感器阵列将以指定的角度或焦距产生光束，传感器将记录该位置的声波交互作用。然后，机架将移动到网格中的下一个点，传感器阵列将重复相同的发射模式，传感器将再次进行记录。重复此过程，直到记录所有网格位置。一旦完成，所有波形可以同步重播，以可视化波前传播(见图2和视频图)。我们发现我们的软件和物理模型通常是匹配的(参见图2中的例子)。</p>
<p>在这一阶段的发展，我们也测试了许多不同的超声换能器与不同的功率，物理尺寸，和波束宽度。为了评估性能，我们把两个相同的换能器放在相距1厘米的地方，相互连接。一个驱动在100 Vpp，而另一个是由发射驱动。结果表明，接收信号最高的换能器具有最佳的发射效率和空气阻抗匹配。我们最终选择了[35]，这是一种直径为12.8 mm、谐振频率为40 kHz、波束宽度为70°的传感器。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75420939-216b9b00-5974-11ea-809b-23fcf9da053d.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h2 id="4、IMPLEMENTATION"><a href="#4、IMPLEMENTATION" class="headerlink" title="4、IMPLEMENTATION"></a>4、IMPLEMENTATION</h2><p>BeamBand由三个主要组件组成。首先是我们的自定义传感器板(图3)，它生成、捕获和处理超声波信号。接下来是一个传感器带，它包含发射和接收信号的超声波传感器(图1A)。我们的概念验证硬件的总成本是220美元。最后，我们有基于膝上型电脑的软件，它从硬件接收数据并执行进一步的处理和机器学习。我们现在更详细地描述这些元素。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75421494-588e7c00-5975-11ea-8960-fe3232a0cb37.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h3 id="4-1-Sensor-Board-and-Transducers"><a href="#4-1-Sensor-Board-and-Transducers" class="headerlink" title="4.1 Sensor Board and Transducers"></a>4.1 Sensor Board and Transducers</h3><p>我们使用8个40 kHz的空中超声压电换能器。单个传感装置包括使用7个换能器发射单个强脉冲，每个换能器具有指定的相移。为了用软件控制的波形来驱动这些传感器，我们构建了一个定制的传感器电路(图3)，它有三个主要组件:高压EMCO SIP100 DC-DC功率调节器[9]、高压放大器和多路模拟前端。一个微小的3.6被用来控制传感器电路[40]，我们超频到240兆赫。</p>
<p>我们配置微控制器来切换它的数字插脚，产生3.3 Vpp 40 kHz的方波。这个信号被放大到100 Vpp来驱动传感器。为了尽量减少跨通道干扰和开关开销，每个传感器都有专门的放大器。为了实现精确的波束形成，我们需要严格控制发射时间。为了最小化延迟，我们直接写入微控制器的I/O映射寄存器，允许我们在一个时钟周期(4.17 ns)中同时切换8个输出引脚。这种严密的控制使我们能够以~0.1°的粒度操作传感器的相对相位。</p>
<p>为了捕获反射的超声波，一个未使用的转换器被配置成一个接收器。在其他7个换能器的点火过程中，我们将换能器固定在地面上，这有助于防止由于声耦合和电噪声引起的误动作。点火完成后，我们断开夹具，将接收传感器连接到模拟前端。然后，我们通过一个固定增益(fc=39 kHz, G=5)的有源高通滤波器传递信号，附加一个增益可调至40倍的放大级。放大后的信号由直流偏置至VADC/2，由单片机的16位ADC以333 kHz采样。所有捕获的波形数据都通过USB传输到笔记本电脑上进行进一步的计算。</p>
<h3 id="4-2-Power-Consumption"><a href="#4-2-Power-Consumption" class="headerlink" title="4.2 Power Consumption"></a>4.2 Power Consumption</h3><p>我们没有优化我们的概念验证硬件的功耗，这是通过它的USB连接5V供电。尽管如此，我们还是测量了电流:大约400mA。在总电流中，250mA来自我们的超频小3.6板(100mA时不超频)。我们的DC-DC转换器消耗大约140mA，其中大部分是转换损耗。所有其他元件，包括我们的换能器，消耗~10mA。</p>
<h3 id="4-3-Transducer-Band"><a href="#4-3-Transducer-Band" class="headerlink" title="4.3 Transducer Band"></a>4.3 Transducer Band</h3><p>如图1所示，我们制作了一个可以戴在手臂或手腕上的带子。我们将8个传感器按马蹄形排列，沿着手臂的轮廓，在皮肤表面上方约1cm处。该带是由EVA泡沫[42]制成，以实现更大的一致性和减少传感器之间的声耦合。用一个可调节的橡皮筋把传感器固定在用户身上。我们选择不包括任何针对手背的传感器，因为手指通常向内连接。值得注意的是，这种布置与我们的物理模拟略有不同(传感器布置成线性阵列);我们用马蹄形布局重新运行了我们的物理模拟，发现波束形成的一致性和分辨率有轻微的偏差。然而，我们认为马蹄铁的紧凑安排超过了这一次要影响。</p>
<h3 id="4-4-Beamforming"><a href="#4-4-Beamforming" class="headerlink" title="4.4 Beamforming"></a>4.4 Beamforming</h3><p>我们选择了5个角度进行波束形成(-45°、-22.5°、0°、+22.5°、+45°)，如图1B所示，这些角度覆盖了手指和手腕运动的典型范围。我们也关注3处距离(图1B): 2厘米，大致与手掌底部相关;8厘米，大致与手指底部相关;和无限聚焦，以捕捉更遥远的特征，如指尖。无限聚焦和0°是相同的波束形成模式，因此，每一轮感知总共包含7个独特的波束形成发射。</p>
<h3 id="4-5-Acoustic-Viewpoints-amp-Waveforms"><a href="#4-5-Acoustic-Viewpoints-amp-Waveforms" class="headerlink" title="4.5 Acoustic Viewpoints &amp; Waveforms"></a>4.5 Acoustic Viewpoints &amp; Waveforms</h3><p>在任何给定的时间，七个传感器作为发射机，一个作为接收器。传感器板循环通过所有的收发组合，从而产生8种配置。对于每个换能器配置，我们发射全部7个波束形成发射，捕获500个反射波形样本(333 kHz采样率)，代表1.5 ms的数据。总的来说，这个过程产生56个记录波形(8种配置7种波束形成序列)，我们称之为“传感帧”(如图1B所示)。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75423470-bae97b80-5979-11ea-8e21-2498b6787e91.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h3 id="4-6-Framerate"><a href="#4-6-Framerate" class="headerlink" title="4.6 Framerate"></a>4.6 Framerate</h3><p>每个波束形成发射序列生成和发射时间为0.5 ms，数据采集时间为1.5 ms。因此，覆盖一个完整的传感器框架(56个波形)需要112毫秒。这导致~8个完整的传感器帧每秒。</p>
<p>出于实验目的，我们捕获了非常大的缓冲区，以查看在更长的范围内是否有有趣的反射。然而，我们的研究(也可以从图4中看到)显示，大多数信号的返回时间都在0.8毫秒之内，如果我们缩短到这个较小的记录周期，帧率就会增加到14赫兹左右。它也可以预先生成波束形成序列并将其存储在内存中，这将进一步节省每帧约28毫秒，并将帧率提高到约22赫兹。进一步的优化可以包括emis的时间复用，这样一个在飞行而另一个返回。</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75425874-83310280-597e-11ea-9e26-70a1215af1c4.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h3 id="4-7-Features-and-Machine-Learning"><a href="#4-7-Features-and-Machine-Learning" class="headerlink" title="4.7 Features and Machine Learning"></a>4.7 Features and Machine Learning</h3><p>我们的机器学习管道首先将硬件捕获的56个输入波形转换成特征。我们将每个波形分割成20个bin，并以每个bin的标准差为特征，得到1120个值。我们使用Scikit-learn的随机森林(默认参数，500棵树)[33]进行分类。所有任务都在标准配置的2013款MacBook Pro 15上完成。</p>
<h2 id="5、GESTURE-SET"><a href="#5、GESTURE-SET" class="headerlink" title="5、GESTURE SET"></a>5、GESTURE SET</h2><p>我们并没有发明一个自定义的手势集，而是特意从文献中选择采用两个手势集来减少设计偏差，并使系统之间能够进行直接比较。第一个是Tomo[50]中定义的手势集。图5(绿色下划线)描述了这七个手势(放松+六个“手势”)。我们还采用了Jung等人定义的手势集[18]，该手势集使手沿着三个轴(两个手腕轴和一个手指轴)伸展或弯曲。图5(紫色下划线)描述了这六种手势。我们在后面的文本中将这个手势设置为“六轴”。注意这些手势集有四种常见的手势，右=手腕弯曲，左=手腕外展，拳头=手指弯曲，放松=手指伸展</p>
<p><img src="https://user-images.githubusercontent.com/17808702/75424512-b8882100-597b-11ea-9ba2-f030a77fc1a9.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<h2 id="6、EVALUATION"><a href="#6、EVALUATION" class="headerlink" title="6、EVALUATION"></a>6、EVALUATION</h2><p>在这项研究中，我们评估了BeamBand的手势分类性能。我们招募了10名参与者(4名女性，平均年龄25岁)，他们的平均手腕直径为5.5厘米(SD=0.8)。这项研究花了大约一个小时完成，花费了20美元。</p>
<h3 id="6-1-Procedure"><a href="#6-1-Procedure" class="headerlink" title="6.1 Procedure"></a>6.1 Procedure</h3><p>参与者在他们非惯用的手腕上戴着束带。(比如手表)。我们所有的参与者都是右撇子，所以束带戴在了左手腕上。每一轮的数据收集包括每一个手势，以随机的顺序执行一次。每个手势保持几秒钟，在此期间记录10个传感器帧。一次会议包括十轮数据收集。为了增加多样性和真实性，我们为每个用户收集了两个会话的数据，其间移除和重新佩戴传感器。这个过程产生了18000个传感器帧(10个传感器帧 9个手势 10轮 2个会话 10个参与者)。</p>
<h3 id="6-2-Within-Session-Accuracy"><a href="#6-2-Within-Session-Accuracy" class="headerlink" title="6.2 Within-Session Accuracy"></a>6.2 Within-Session Accuracy</h3><p>为了模拟系统在首次佩戴时进行校准时的手势识别性能，我们进行了一项leave-one-round-out交叉验证，我们在一个会话中进行了九轮训练，并在第十轮(所有组合)进行了测试。我们独立地对两个阶段重复这一步骤，并取平均值。在完整的9类组合手势集中，所有参与者会话内的平均准确率为90.2% (SD=3.7)。在Tomo手势集中，会话内的平均准确率为92.5% (SD=2.2)，而六轴手势集的准确率为94.6% (SD=3.4)。最大的错误来源是相似的握拳手势之间的混淆，如拳头和大拇指朝上，这些手势占手势集总错误的15.2%。混淆矩阵可以在图6中找到。</p>
<h3 id="6-3-Across-Session-Accuracy"><a href="#6-3-Across-Session-Accuracy" class="headerlink" title="6.3 Across-Session Accuracy"></a>6.3 Across-Session Accuracy</h3><p>对身体感知系统的一个重大挑战是在磨损会话中良好执行的能力。为了评估BeamBand被重新磨损后性能的下降，我们对每个参与者进行了一次跨验证，即对会话1中的所有数据进行训练，并对会话2中的所有数据进行测试，反之亦然。在完整的9类组合手势集中，所有参与者的平均跨会话准确率为81.4% (SD=15.9)。Tomo手势组的平均跨会话准确率为86.0% (SD-12.7)，六轴手势组的平均跨会话准确率为89.4% (SD=10.9)。我们发现拳头和大拇指向上之间也有类似的混淆，占手势设置总错误的9.1%。然而，在重新佩戴传感器后，其他手势似乎没有受到影响(例如，左手腕弯曲的频率分别为94.2%和96.2%)。本实验的混淆矩阵见图7。</p>
<h3 id="6-4-Across-User-Accuracy"><a href="#6-4-Across-User-Accuracy" class="headerlink" title="6.4 Across-User Accuracy"></a>6.4 Across-User Accuracy</h3><p>对身体系统的另一个重大挑战是一次训练的能力，并为所有用户工作(即。，而不需要进行人员培训或校准)。为了调查这一可能性，我们对每个参与者进行了一次“一用户退出”交叉验证，我们对9个参与者的两个会话中的所有数据进行训练，并对第10个参与者的两个会话中的所有数据进行测试(所有组合)。在完整的9类组合手势集中，平均跨用户准确率为44.2% (SD=8.8)。在Tomo手势集中，平均跨用户准确率为51.7% (SD=10.4)，而在六轴手势集中，平均跨用户准确率为63.2% (SD=8.5)。这种低性能表明用户的手是不同的，手势的表现也不同。尽管如此，一些手势在不同用户之间似乎更一致，比如手腕弯曲和径向偏差，分别为80.1%和79.2%。</p>
<h3 id="6-5-Comparison-to-Prior"><a href="#6-5-Comparison-to-Prior" class="headerlink" title="6.5 Comparison to Prior"></a>6.5 Comparison to Prior</h3><p>结果我们的会话内结果类似于我们从中绘制手势集的两个系统。在会话中，Jung等人的[18]报告了6种手势的95.4%的准确率，而手腕上的Tomo[50]在7种手势的准确率为96.6%。在这些方面，BeamBand分别达到了92.5%和94.6%。当手势集合并(9个类)时，BeamBand的准确率为90.2%。</p>
<p>我们的系统与其他自定义手势集系统的性能也相当。最值得注意的是，SensIR[29]报告12种手势的准确率为93.3%，zSense[47]报告9种手势的准确率为94.8%，Skinput[15]报告4种手指敲击手势的准确率为96.8%，而Mime[6]报告4种手势的准确率约为95%。注意，这些系统都不评估跨会话或跨用户的准确性。</p>
<p>很少有系统评估跨会话的准确性，这对身体感知系统来说是特别具有挑战性的。Tomo报告了7种手势在整个会话中的准确率为65.3%。在相同的手势设置下，BeamBand达到86.0%。Jung等人没有报告交叉会话的准确性，但作为参考，BeamBand在其手势集上实现了89.4%的准确性。</p>
<p>最罕见的是评估跨用户准确性的系统(除了磨损的计算机视觉系统，它往往是健壮的)。Tomo报告了7种手势对手腕的跨用户准确率为38.8%，而BeamBand在同一组手势上的准确率为51.7%。我们在文献中找不到其他的比较点。</p>
<h3 id="6-6-Robustness-to-Sleeve-Occlusion"><a href="#6-6-Robustness-to-Sleeve-Occlusion" class="headerlink" title="6.6 Robustness to Sleeve Occlusion"></a>6.6 Robustness to Sleeve Occlusion</h3><p>与光不同，超声波可以穿透薄织物。我们在开发过程中发现，我们可以把袖子卷到传感器上，训练被遮挡的系统，而对精度的影响最小。为了更正式地测量封套的稳健性，我们放置了两个相同的换能器，面对面，相距8厘米。我们驱动一个传感器使用功能发生器(40khz, 10vpp)，而另一个连接到示波器。然后，我们在发射换能器上覆盖了一层不同的织物来模拟套筒堵塞。我们测试了10种不同材质、厚度和编织密度的面料(图8)。</p>
<p>当厚度与信号强度相关时，一个更重要的因素是编织密度。例如，涤纶衬衫是我们测试过的面料中最薄的，但对性能的影响最大。相反，羊毛衫(低密度编织)是我们性能更好的面料之一，尽管它是我们最厚的面料。</p>
<h2 id="7、STRENGTHS-amp-WEAKNESSES"><a href="#7、STRENGTHS-amp-WEAKNESSES" class="headerlink" title="7、STRENGTHS &amp; WEAKNESSES"></a>7、STRENGTHS &amp; WEAKNESSES</h2><p>虽然BeamBand与以前的系统相比具有竞争力，但它还不够精确，例如，对于消费类设备来说。然而，作为概念的证明，技术方法看起来很有前途。为了实现“开箱即用”的手势识别，需要进行更多的工作来开发一个可推广的模型。通过广泛的参与者收集更多的数据可能会提高健壮性。从经典的机器学习方法转向深度学习可能也是有价值的。我们还怀疑增加一个校准台，使腕带的定位可以提高整个会话和跨用户的准确性。</p>
<p>未来研究的另一个方向是探索不同频率的超声波。运行在40khz的换能器无处不在(因此价格低廉)，但几乎可以肯定，它不是进行手势识别的最佳频率(约8.5mm的波长可能太大了)。更高的频率可以更好地感知精细的动作和手势，尽管代价是空气中更高的信号衰减，这必须通过更高的驱动电压或更敏感的模拟前端来克服。</p>
<p>虽然马蹄形布局应该允许在垂直于手掌的轴上有一定程度的波束形成，但我们把我们的阵列看作是线性的，它允许波束沿着平行于手掌的平面形成。更先进的波束形成模式，或二维传感器阵列，将使三维光栅扫描类似的能力，可以提供更丰富的信号。毫无疑问，它将有助于识别手势，如拳头和大拇指朝上，这在横截面上看起来相当相似。</p>
<p>我们使用通用微控制器来促进研究和快速原型。在商业实现中，波束形成模式将保存在内存中，而专用的、节能的硬件(如asic)将驱动整个传感过程。减少感知占空比和仅在检测到变化时以全帧率运行也可以提高功耗。传感原理本身是相当节能的;换能器本身几乎不需要任何动力来驱动。因此，我们相信通过适当的工程设计，可以实现一个不受束缚的、自包含的BeamBand版本。</p>
<p>还有一些重要的物理约束。例如，我们需要把换能器从皮肤上拿起来，以便在手掌底部的凸起上投射出声学效果，这样可以增加最小的厚度。另一个限制是传感器的尺寸，我们选择的传感器直径几乎为13毫米。然而，内部的压电层直径约为5毫米，这表明更紧密的集成是可能的。此外，超声换能器并不局限于圆柱形外壳;医学超声利用小方元素安排在一条。实际上，BeamBand可以坐在智能手表侧面的一个透明塑料窗口后面，这与医用超声波棒非常相似。</p>
<h2 id="8、CONCLUSION"><a href="#8、CONCLUSION" class="headerlink" title="8、CONCLUSION"></a>8、CONCLUSION</h2><p>摘要提出了一种基于超声波波束形成技术的手形识别方法。BeamBand以不同的角度和焦点将超声波的前沿投射到用户的手上，并测量反射回波段的声波。我们从文献中评估了两个手势集，我们的用户研究显示，无论是会话内还是跨会话，都有很好的准确性。我们希望我们的努力将作为一个催化剂，深入研究超声波波束形成，使新的相互作用。</p>
<h2 id="ACKNOWLEDGEMENTS"><a href="#ACKNOWLEDGEMENTS" class="headerlink" title="ACKNOWLEDGEMENTS"></a>ACKNOWLEDGEMENTS</h2><p>这项工作得到了帕克德基金会和斯隆基金会的慷慨资助。我们还要感谢Robert Xiao教授在嵌入式开发方面的帮助，还要感谢Evi Bernitsas，是他激发了我们对人类输入传感波束形成的兴趣。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>BeamBand-Hand Gesture Sensing with Ultrasonic Beamforming</div>
      <div>https://zhangfuli.github.io/2020/02/27/BeamBand-Hand-Gesture-Sensing-with-Ultrasonic-Beamforming/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>张富利</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2020年2月27日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/03/08/you-get%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91/" title="you-get下载视频">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">you-get下载视频</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/02/23/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%80%BB%E7%BB%93/" title="区块链总结">
                        <span class="hidden-mobile">区块链总结</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
